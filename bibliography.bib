@article{Colquhoun2014,
         abstract = {If you use P = 0.05 to suggest that you have made a discovery, you’ll be wrong at least 30\% of the time. If, as is often the case, experiments are under-powered, you’ll de wrong most of the time. This conclusion is demonstrated from several points of view. First, tree diagrams which show the close analogy with the screening test problem. Similar conclusions are drawn by repeated simulations of t tests. These mimic what’s done in real life, which makes the results more persuasive The simulation method is used is used also to evaluate the extent effect sizes are over-estimated, especially in under-powered experiments. A script is supplied to allow the reader to do simulations themselves, with numbers appropriate for their own work. The interpretation of an observed result of, say, P = 0.047 is investigated from several points of view. It is concluded that if you wish to keep your false discovery rate below 5\%, you need to use a 3-sigma rule, or to insist on P ≤ 0.001. And never use the word “significant”.},
         archivePrefix = {arXiv},
         arxivId = {1407.5296},
         author = {Colquhoun, David},
         doi = {10.1098/rsos.140216},
         eprint = {1407.5296},
         file = {:home/matthew/Documents/Mendeley Desktop/Colquhoun - 2014 - An investigation of the false discovery rate and the misinterpretation of P values.pdf:pdf},
         issn = {2054-5703},
         journal = {Royal Society Open Science},
         keywords = {computational biology,statistics},
         number = {140216},
         pages = {1--15},
         title = {{An investigation of the false discovery rate and the misinterpretation of P values}},
         url = {10.1098/rsos.140216},
         volume = {1},
         year = {2014}
}
